{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 30780,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16244314489928524,
      "grad_norm": 1.064329981803894,
      "learning_rate": 1.6244314489928523e-05,
      "loss": 6.1258,
      "step": 500
    },
    {
      "epoch": 0.3248862897985705,
      "grad_norm": 0.1847565621137619,
      "learning_rate": 3.248862897985705e-05,
      "loss": 4.8326,
      "step": 1000
    },
    {
      "epoch": 0.4873294346978557,
      "grad_norm": 0.6931942701339722,
      "learning_rate": 4.8732943469785574e-05,
      "loss": 4.4286,
      "step": 1500
    },
    {
      "epoch": 0.649772579597141,
      "grad_norm": 0.20435988903045654,
      "learning_rate": 6.49772579597141e-05,
      "loss": 4.3601,
      "step": 2000
    },
    {
      "epoch": 0.8122157244964262,
      "grad_norm": 0.4278944134712219,
      "learning_rate": 8.122157244964262e-05,
      "loss": 4.3304,
      "step": 2500
    },
    {
      "epoch": 0.9746588693957114,
      "grad_norm": 0.5611976385116577,
      "learning_rate": 9.746588693957115e-05,
      "loss": 4.3064,
      "step": 3000
    },
    {
      "epoch": 1.1371020142949968,
      "grad_norm": 0.4825248122215271,
      "learning_rate": 9.847664428561115e-05,
      "loss": 4.2861,
      "step": 3500
    },
    {
      "epoch": 1.299545159194282,
      "grad_norm": 0.7936796545982361,
      "learning_rate": 9.667172045339687e-05,
      "loss": 4.2711,
      "step": 4000
    },
    {
      "epoch": 1.4619883040935673,
      "grad_norm": 0.5434879064559937,
      "learning_rate": 9.486679662118259e-05,
      "loss": 4.2587,
      "step": 4500
    },
    {
      "epoch": 1.6244314489928526,
      "grad_norm": 0.7053227424621582,
      "learning_rate": 9.30618727889683e-05,
      "loss": 4.2421,
      "step": 5000
    },
    {
      "epoch": 1.7868745938921378,
      "grad_norm": 0.6937035322189331,
      "learning_rate": 9.125694895675403e-05,
      "loss": 4.2241,
      "step": 5500
    },
    {
      "epoch": 1.949317738791423,
      "grad_norm": 0.5792029500007629,
      "learning_rate": 8.945202512453975e-05,
      "loss": 4.2069,
      "step": 6000
    },
    {
      "epoch": 2.1117608836907085,
      "grad_norm": 0.9428079724311829,
      "learning_rate": 8.764710129232548e-05,
      "loss": 4.1928,
      "step": 6500
    },
    {
      "epoch": 2.2742040285899936,
      "grad_norm": 0.7859111428260803,
      "learning_rate": 8.584217746011119e-05,
      "loss": 4.1811,
      "step": 7000
    },
    {
      "epoch": 2.4366471734892787,
      "grad_norm": 0.7486078143119812,
      "learning_rate": 8.40372536278969e-05,
      "loss": 4.1725,
      "step": 7500
    },
    {
      "epoch": 2.599090318388564,
      "grad_norm": 0.6133935451507568,
      "learning_rate": 8.223232979568263e-05,
      "loss": 4.1642,
      "step": 8000
    },
    {
      "epoch": 2.761533463287849,
      "grad_norm": 0.7493299245834351,
      "learning_rate": 8.042740596346835e-05,
      "loss": 4.1586,
      "step": 8500
    },
    {
      "epoch": 2.9239766081871346,
      "grad_norm": 0.9010229110717773,
      "learning_rate": 7.862248213125406e-05,
      "loss": 4.1537,
      "step": 9000
    },
    {
      "epoch": 3.0864197530864197,
      "grad_norm": 1.0275869369506836,
      "learning_rate": 7.681755829903978e-05,
      "loss": 4.149,
      "step": 9500
    },
    {
      "epoch": 3.248862897985705,
      "grad_norm": 0.7088145613670349,
      "learning_rate": 7.50126344668255e-05,
      "loss": 4.1447,
      "step": 10000
    },
    {
      "epoch": 3.4113060428849904,
      "grad_norm": 0.728874683380127,
      "learning_rate": 7.320771063461122e-05,
      "loss": 4.1413,
      "step": 10500
    },
    {
      "epoch": 3.5737491877842755,
      "grad_norm": 0.7890949845314026,
      "learning_rate": 7.140278680239694e-05,
      "loss": 4.137,
      "step": 11000
    },
    {
      "epoch": 3.7361923326835607,
      "grad_norm": 0.8669670224189758,
      "learning_rate": 6.959786297018266e-05,
      "loss": 4.1334,
      "step": 11500
    },
    {
      "epoch": 3.898635477582846,
      "grad_norm": 0.8045768737792969,
      "learning_rate": 6.779293913796838e-05,
      "loss": 4.1304,
      "step": 12000
    },
    {
      "epoch": 4.061078622482131,
      "grad_norm": 0.7377500534057617,
      "learning_rate": 6.59880153057541e-05,
      "loss": 4.1286,
      "step": 12500
    },
    {
      "epoch": 4.223521767381417,
      "grad_norm": 0.739237368106842,
      "learning_rate": 6.418309147353982e-05,
      "loss": 4.1259,
      "step": 13000
    },
    {
      "epoch": 4.385964912280702,
      "grad_norm": 1.060322880744934,
      "learning_rate": 6.237816764132554e-05,
      "loss": 4.1231,
      "step": 13500
    },
    {
      "epoch": 4.548408057179987,
      "grad_norm": 0.8126741647720337,
      "learning_rate": 6.057324380911126e-05,
      "loss": 4.1196,
      "step": 14000
    },
    {
      "epoch": 4.710851202079272,
      "grad_norm": 0.9361457228660583,
      "learning_rate": 5.876831997689698e-05,
      "loss": 4.1162,
      "step": 14500
    },
    {
      "epoch": 4.8732943469785575,
      "grad_norm": 0.9107763171195984,
      "learning_rate": 5.69633961446827e-05,
      "loss": 4.1166,
      "step": 15000
    },
    {
      "epoch": 5.035737491877843,
      "grad_norm": 0.9858542680740356,
      "learning_rate": 5.5158472312468415e-05,
      "loss": 4.1127,
      "step": 15500
    },
    {
      "epoch": 5.198180636777128,
      "grad_norm": 1.166934847831726,
      "learning_rate": 5.335354848025414e-05,
      "loss": 4.1109,
      "step": 16000
    },
    {
      "epoch": 5.360623781676413,
      "grad_norm": 1.0287890434265137,
      "learning_rate": 5.154862464803986e-05,
      "loss": 4.1089,
      "step": 16500
    },
    {
      "epoch": 5.523066926575699,
      "grad_norm": 0.8321431279182434,
      "learning_rate": 4.974370081582557e-05,
      "loss": 4.1065,
      "step": 17000
    },
    {
      "epoch": 5.685510071474984,
      "grad_norm": 0.8377798795700073,
      "learning_rate": 4.7938776983611294e-05,
      "loss": 4.1048,
      "step": 17500
    },
    {
      "epoch": 5.847953216374269,
      "grad_norm": 0.9228895902633667,
      "learning_rate": 4.613385315139701e-05,
      "loss": 4.1037,
      "step": 18000
    },
    {
      "epoch": 6.010396361273554,
      "grad_norm": 0.9582605957984924,
      "learning_rate": 4.432892931918273e-05,
      "loss": 4.1014,
      "step": 18500
    },
    {
      "epoch": 6.172839506172839,
      "grad_norm": 0.847399115562439,
      "learning_rate": 4.252400548696845e-05,
      "loss": 4.0994,
      "step": 19000
    },
    {
      "epoch": 6.3352826510721245,
      "grad_norm": 1.0953741073608398,
      "learning_rate": 4.0719081654754174e-05,
      "loss": 4.0988,
      "step": 19500
    },
    {
      "epoch": 6.49772579597141,
      "grad_norm": 0.9800584316253662,
      "learning_rate": 3.8914157822539895e-05,
      "loss": 4.0962,
      "step": 20000
    },
    {
      "epoch": 6.660168940870696,
      "grad_norm": 1.0530997514724731,
      "learning_rate": 3.710923399032561e-05,
      "loss": 4.0961,
      "step": 20500
    },
    {
      "epoch": 6.822612085769981,
      "grad_norm": 0.878154993057251,
      "learning_rate": 3.530431015811133e-05,
      "loss": 4.0937,
      "step": 21000
    },
    {
      "epoch": 6.985055230669266,
      "grad_norm": 1.1170004606246948,
      "learning_rate": 3.3499386325897046e-05,
      "loss": 4.0931,
      "step": 21500
    },
    {
      "epoch": 7.147498375568551,
      "grad_norm": 1.169985294342041,
      "learning_rate": 3.169446249368277e-05,
      "loss": 4.0904,
      "step": 22000
    },
    {
      "epoch": 7.309941520467836,
      "grad_norm": 1.123390793800354,
      "learning_rate": 2.9889538661468486e-05,
      "loss": 4.09,
      "step": 22500
    },
    {
      "epoch": 7.472384665367121,
      "grad_norm": 0.9965802431106567,
      "learning_rate": 2.8084614829254207e-05,
      "loss": 4.0895,
      "step": 23000
    },
    {
      "epoch": 7.6348278102664064,
      "grad_norm": 1.167660117149353,
      "learning_rate": 2.6279690997039925e-05,
      "loss": 4.0894,
      "step": 23500
    },
    {
      "epoch": 7.797270955165692,
      "grad_norm": 0.7868677973747253,
      "learning_rate": 2.4474767164825647e-05,
      "loss": 4.087,
      "step": 24000
    },
    {
      "epoch": 7.959714100064978,
      "grad_norm": 0.8932055234909058,
      "learning_rate": 2.2669843332611365e-05,
      "loss": 4.0864,
      "step": 24500
    },
    {
      "epoch": 8.122157244964262,
      "grad_norm": 0.7587926983833313,
      "learning_rate": 2.0864919500397083e-05,
      "loss": 4.0843,
      "step": 25000
    },
    {
      "epoch": 8.284600389863547,
      "grad_norm": 1.0415128469467163,
      "learning_rate": 1.9059995668182805e-05,
      "loss": 4.0835,
      "step": 25500
    },
    {
      "epoch": 8.447043534762834,
      "grad_norm": 1.0200064182281494,
      "learning_rate": 1.7255071835968523e-05,
      "loss": 4.0842,
      "step": 26000
    },
    {
      "epoch": 8.609486679662119,
      "grad_norm": 1.0441691875457764,
      "learning_rate": 1.545014800375424e-05,
      "loss": 4.0847,
      "step": 26500
    },
    {
      "epoch": 8.771929824561404,
      "grad_norm": 1.057242512702942,
      "learning_rate": 1.364522417153996e-05,
      "loss": 4.0838,
      "step": 27000
    },
    {
      "epoch": 8.93437296946069,
      "grad_norm": 0.7899695634841919,
      "learning_rate": 1.1840300339325682e-05,
      "loss": 4.0813,
      "step": 27500
    },
    {
      "epoch": 9.096816114359974,
      "grad_norm": 0.7108189463615417,
      "learning_rate": 1.00353765071114e-05,
      "loss": 4.0812,
      "step": 28000
    },
    {
      "epoch": 9.25925925925926,
      "grad_norm": 1.0282915830612183,
      "learning_rate": 8.23045267489712e-06,
      "loss": 4.0821,
      "step": 28500
    },
    {
      "epoch": 9.421702404158545,
      "grad_norm": 0.9008634090423584,
      "learning_rate": 6.425528842682839e-06,
      "loss": 4.0805,
      "step": 29000
    },
    {
      "epoch": 9.58414554905783,
      "grad_norm": 0.9054492115974426,
      "learning_rate": 4.620605010468559e-06,
      "loss": 4.079,
      "step": 29500
    },
    {
      "epoch": 9.746588693957115,
      "grad_norm": 0.8633396029472351,
      "learning_rate": 2.8156811782542777e-06,
      "loss": 4.082,
      "step": 30000
    },
    {
      "epoch": 9.9090318388564,
      "grad_norm": 0.8518039584159851,
      "learning_rate": 1.0107573460399973e-06,
      "loss": 4.0802,
      "step": 30500
    }
  ],
  "logging_steps": 500,
  "max_steps": 30780,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.501307525480448e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
